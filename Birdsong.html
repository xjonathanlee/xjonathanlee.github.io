<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jonathan Lee - Dawn Chorus</title>

  <link href="css/main.css" rel="stylesheet">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="js/salmon3.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.5.0/dist/lazyload.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
<script src="https://cdn.jsdelivr.net/npm/@observablehq/plot@0.6"></script>
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,700" rel="stylesheet">
<script src="js/followcursor.js"></script>
<link rel="icon" href="img/favicon.ico">

</head>

<body>

  <nav class="header-nav">
    <a href="index.html" class="nav-item">Home</a>
    <a href="about.html" class="nav-item">About</a>
  </nav>

<img class="full-bleed lazy" src="img/lazy-load.jpg" data-src="img/birdsong/birdsong1.gif" alt="gif of steveston" width="1080" height="1000">

  <section class="main-content">
    <h1 class="project-title">Dawn Chorus</h1>
    <p class="detail-intro">
      Recording nature has been done since the beginning of communication, from plentiful hunting locations to ample gathering spots, we've needed this information recorded some type of <i>place</i>. In this design study I've attempted to illustrate and abstract the "dawn chorus" and the "evening chorus" of birds in my local area. 
    </p>

    <div class="sub-content-group">
      <ul class="sub-content-item">
        <li><em>Roles:</em>Interaction Design, Art Direction, Research Creation</li>
        <li><em>Tools:</em> Adobe Illustrator,Nature Journaling, Audio Identification, Data Synthesis</li>
        <li><em>Status:</em> Ongoing</li>
      </ul>
      <ul class="sub-content-item">
        <li><em>Context:</em> Personal Project</li>
         <li><em>Deliverables:</em> <a href="#">Bird Scarf</a></li>
      </ul>
    </div>

    <h2>Problem</h2>

    <p>Using Nature Journaling as a catalyst to create, how might we abstract the "Dawn Chorus"?</p>

    <h2>Design Process</h2>
    <p>I've been a nature photographer for about 3 years, and in order to catalogue new insights in the field I've taken up Nature Journaling during fleeting moments of quiet. Nature Journaling has opened my eyes to asking questions about the nature world and what our place is in it. As a side project I wanted to look at bird song and how we could look at Bird Song as a visual representation of place. This project started as a love letter to Giogia Lupi's "Dear Data" and over time morphed into something I cherish. I'd love to chat more about this process and travel the world to make scarves out of different choruses.</p> 

<!-- Demo1 -->
 <!--    <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">A snapshot of my design process + sketches</p> -->

    
    <h2>Designing a Visual Language</h2>
    <p>Taking inspiration from Nature Journaling Techniques from the Audabon Society I encountered a method for catagorizing and recording bird song visually. From this I extrapolated a visual language based on call frequency, call length, and loudness based on location. Drawing from my musical background it was easy to see how we could add musical symbols to the "score".</p> 

    <p>Below you can see John Muirs Laws illustrating this principal: </p>

    <div class="videocontainer">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/3JsOf9CROCM?si=ceG38TtFu8FASWlv" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div>

    <h2>Auditory Sight and Seeing</h2>
    <p>With birding and spatial audio, I developed a visual language to catagorize and catalogue bird numbers and estimations of size that fit the visual pattern. By picking apart observations at a granular scale during an "exposure" we can give users a visual sense of where and when birds come into the picture to paint a landscape. Birds can be counted through observation, and tracked to their behavior patterns based on phenotype. While it is not an "accurate" portrayal of the exact species at that moment, it offers a glimpse into that slice of time on that particular day. Over a period this visual system could be supportive of a robust information system as a catalogue. The intent is to catalogue the data provided, but not take a picture.</p>
    
<!-- Demo1 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Visual Reference Guide</p> -->

    <h2>Data Management and Sound Forms</h2>

    <p>Bird Song as a medium is difficult to abstract because of its variance in sound texture and call length. In order to present a consistent aesthetic I used this paper(<a href="https://ui.adsabs.harvard.edu/abs/2002Natur.417..351B/abstract">https://ui.adsabs.harvard.edu/abs/2002Natur.417..351B/abstract</a>) as a metric to help reel in expectations of what an abstracted sound could look like. By diffrientiating bird song by length and by type (and by including a way to catagorize some birds as "unknown") this helped me create and define a color + texture pallette.</p>

<!-- Demo1 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">How to read</p> -->

    <h2>Visual Impact</h2>

<!-- Maybe an abstract image here or a gif that shows interaction? -->

    <p>Initially I looked at the abstraction of birdsong similar to reading sheet music. Tying this together visually with observations I noticed that many bird songs operate in the same frequency range. To get around this challenge I used a visual overlay to group different birds together, reducing complexity and increasing readability. By linking several of the same "songs" together on the weave, we could isolate and observe patterns in different birds and calls over time.</p>

<!-- Slide Show of scanned sketches -->
<!--     <img class="full-bleed lazy" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Notebook Sketches</p> -->

    <p> I return to the idea of musicality in later explorations,while also exploring the idea of sound and bi-directional mapping across mediums. By creating a way to illustrate time and direction as well as "intrusive songs" the goal was to create a sensory experience relative to timescale, allowing each observation to have its own "voice" musically.</p>

<!-- Demo1 -->
<!--     <img class="full-bleed lazy" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Explorations in design(2)</p> -->

    <p>Drawing on Giogia Lupis ideas of "Data Humanism" I sought to allow the medium itself to be used as a "holder" affording a kinetic component to the sound map within. By positioning the scarf in the right area and place or by following the path I followed, I hoped to include a more sensory approach to just a conventional "data map".</p>

<!-- Demo1 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Data Humanism Picture</p> -->

    <h2> Functional vs Expressive </h2>
    <p>
      "Form following function" was the result of multiple iterations and studies of placement and scale. More specifically I wanted to look at how displaying the data aesthetically could lead to a better product.The hardest part here was finding a visual that showed cohesion and was bold enough to stand on its own. As I began to diverge from the initial idea of data formation, I explored other ideas that drew on pattern, repetition and more subtle encoding.
    </p>
      <!-- Demo1 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Visual for maximum functionality.</p> -->

    <p>
      Expressing sound as a map was the result of multiple iterations and studies of readability and cohesion. More specifically I wanted to look at how displaying the data differently affected the perception of the piece. The hardest part was keeping a balance between readability and aesthetics, as the more "human" the data got, the more it limited readability. For this exploration I wanted to focus on the material of the scarf, exploring radial symmetry, sound cataloging and deep encoding of data.
    </p>

    <!-- Demo2 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Redrawing the visual for maximum expressiveness</p> -->


    <h2> Final Product </h2>
    <!-- Demo1 -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Final Result</p> -->

    <p>
      The final product looked at each call as an individual bird signature, repeating a "capital call" for a distinct bird. Using scale and repetition to drive home the idea of a "chorus". This was the piece that I struggled most with as it sacrificed readability for the entire series. But was expressive enough to decode through inspection.
    </p>
<!-- How to Read it -->
<!--     <img class="full-bleed lazy full-screenimage" src="img/lazy-load.jpg" data-src="#" alt="#">
    <p class="annotate">Final Result</p> -->

    <h2> Reflection </h2>
    <p> A project that challenged my notion of "good" and "articulate" design by stressing how we catalogue map, and synthesize data in real time. Taking walks daily, opening my mind and sketching helped me negotiate the boundaries of my current design practice and help me better drill down to the core copetencies that I felt like I was missing. This project allowed me to explore data and translate that to a "felt" experience through a different medium. With luck, I can send these scarfs out as collection pieces on specific days, otherwise I am content with having one for special occasions that can tell a story. </p>
    <br>

   <div class="footer-grid">
    <a  class="footerproject footer-col1" href="semalt.html">&larr; SIAR </a>
    <a  class="footerproject footer-col2" href="makePretty.html"> makePretty &rarr;</a>

</div>
  </section>
  <script src="js/lazyload.js"></script>
    <script>
    console.log("BFBFBF");

      // Don't use window.onLoad like this in production, because it can only listen to one function.
      window.onload = function() {
        // Expose to window namespase for testing purposes
      };

      var prev_handler = window.onload;
      window.onload = function(){
        if(prev_handler){
          prev_handler();
        }
        console.log("nuignignin");
        var elements = document.querySelectorAll('.full-screenimage');
        Intense(elements);
    };

window.requestAnimFrame = (function(){
  return  window.requestAnimationFrame       ||
          window.webkitRequestAnimationFrame ||
          window.mozRequestAnimationFrame    ||
          function( callback ){
            window.setTimeout(callback, 1000 / 60);
          };
})();

window.cancelRequestAnimFrame = ( function() {
    return window.cancelAnimationFrame          ||
        window.webkitCancelRequestAnimationFrame    ||
        window.mozCancelRequestAnimationFrame       ||
        window.oCancelRequestAnimationFrame     ||
        window.msCancelRequestAnimationFrame        ||
        clearTimeout
} )();


var Intense = (function() {

    'use strict';

    var KEYCODE_ESC = 27;

    // Track both the current and destination mouse coordinates
    // Destination coordinates are non-eased actual mouse coordinates
    var mouse = { xCurr:0, yCurr:0, xDest: 0, yDest: 0 };

    var horizontalOrientation = true;

    // Holds the animation frame id.
    var looper;
  
    // Current position of scrolly element
    var lastPosition, currentPosition = 0;
    
    var sourceDimensions, target;
    var targetDimensions = { w: 0, h: 0 };
  
    var container;
    var containerDimensions = { w: 0, h:0 };
    var overflowArea = { x: 0, y: 0 };

    // Overflow variable before screen is locked.
    var overflowValue;

    /* -------------------------
    /*          UTILS
    /* -------------------------*/

    // Soft object augmentation
    function extend( target, source ) {

        for ( var key in source )

            if ( !( key in target ) )

                target[ key ] = source[ key ];

        return target;
    }

    // Applys a dict of css properties to an element
    function applyProperties( target, properties ) {

      for( var key in properties ) {
        target.style[ key ] = properties[ key ];
      }
    }

    // Returns whether target a vertical or horizontal fit in the page.
    // As well as the right fitting width/height of the image.
    function getFit( 

      source ) {

      var heightRatio = window.innerHeight / source.h;

      if( (source.w * heightRatio) > window.innerWidth ) {
        return { w: source.w * heightRatio, h: source.h * heightRatio, fit: true };
      } else {
        var widthRatio = window.innerWidth / source.w;
        return { w: source.w * widthRatio, h: source.h * widthRatio, fit: false };
      }
    }

    /* -------------------------
    /*          APP
    /* -------------------------*/

    function startTracking( passedElements ) {

      var i;

      // If passed an array of elements, assign tracking to all.
      if ( passedElements.length ) {

        // Loop and assign
        for( i = 0; i < passedElements.length; i++ ) {
          track( passedElements[ i ] );
        }

      } else {
          track( passedElements );
      }
    }

    function track( element ) {

      // Element needs a src at minumun.
      if( element.getAttribute( 'src') || element.src ) {
        element.addEventListener( 'click', function() {
          init( this );
        }, false );
      }
    }
  
    function start() { 
      loop();
    }
   
    function stop() {
      cancelRequestAnimFrame( looper );
    }

    function loop() {
        looper = requestAnimFrame(loop);
        positionTarget();      
    }

    // Lock scroll on the document body.
    function lockBody() {

      overflowValue = document.body.style.overflow;
      document.body.style.overflow = 'hidden';
    }

    // Unlock scroll on the document body.
    function unlockBody() {
      document.body.style.overflow = overflowValue;
    }

    function createViewer( title, caption ) {

      /*
       *  Container
       */
      var containerProperties = {
        'backgroundColor': 'rgba(0,0,0,0.8)',
        'width': '100%',
        'height': '100%',
        'position': 'fixed',
        'top': '0px',
        'left': '0px',
        'overflow': 'hidden',
        'zIndex': '999999',
        'margin': '0px',
        'webkitTransition': 'opacity 150ms cubic-bezier( 0, 0, .26, 1 )',
        'MozTransition': 'opacity 150ms cubic-bezier( 0, 0, .26, 1 )',
        'transition': 'opacity 150ms cubic-bezier( 0, 0, .26, 1 )',
        'opacity': '0'
      }
      container = document.createElement( 'figure' );
      container.appendChild( target );
      applyProperties( container, containerProperties );

      var imageProperties = {
        'cursor': 'url( "data:image/png;base64,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" ) 25 25, auto'
      }
      applyProperties( target, imageProperties );

      setDimensions();

      mouse.xCurr = mouse.xDest = window.innerWidth / 2;
      mouse.yCurr = mouse.yDest = window.innerHeight / 2;
      
      document.body.appendChild( container );
      setTimeout( function() {
        container.style[ 'opacity' ] = '1';
      }, 10);
    }

    function removeViewer() {

      unlockBody();
      unbindEvents();
      document.body.removeChild( container );
    }

    function setDimensions() {

      // Manually set height to stop bug where 
      var imageDimensions = getFit( sourceDimensions );
      target.width = imageDimensions.w;
      target.height = imageDimensions.h;
      horizontalOrientation = imageDimensions.fit;

      targetDimensions = { w: target.width, h: target.height };
      containerDimensions = { w: window.innerWidth, h: window.innerHeight };
      overflowArea = {x: containerDimensions.w - targetDimensions.w, y: containerDimensions.h - targetDimensions.h};

    }

    function init( element ) {

      var imageSource = element.getAttribute( 'src') || element.src;
      
      var img = new Image();
      img.onload = function() {

        sourceDimensions = { w: img.width, h: img.height }; // Save original dimensions for later.
        target = this;
        createViewer( title, caption );
        lockBody();
        bindEvents();
        loop();
      }

      img.src = imageSource;
    }

    function bindEvents() {

      container.addEventListener( 'mousemove', onMouseMove,   false );
      container.addEventListener( 'touchmove', onTouchMove,   false );
      window.addEventListener(    'resize',    setDimensions, false );
      window.addEventListener(    'keyup',     onKeyUp,       false );
      target.addEventListener(    'click',     removeViewer,  false );
    }

    function unbindEvents() {

      container.removeEventListener( 'mousemove', onMouseMove,   false );
      container.removeEventListener( 'touchmove', onTouchMove,   false);
      window.removeEventListener(    'resize',    setDimensions, false );
      window.removeEventListener(    'keyup',     onKeyUp,       false );
      target.removeEventListener(    'click',     removeViewer,  false )
    }
  
    function onMouseMove( event ) {

      mouse.xDest = event.clientX;
      mouse.yDest = event.clientY;
    }

    function onTouchMove( event ) {

      event.preventDefault(); // Needed to keep this event firing.
      mouse.xDest = event.touches[0].clientX;
      mouse.yDest = event.touches[0].clientY;
    }

    // Exit on excape key pressed;
    function onKeyUp( event ) {

      event.preventDefault();
      if ( event.keyCode === KEYCODE_ESC ) {
        removeViewer();
      } 
    }
  
    function positionTarget() {

      mouse.xCurr += ( mouse.xDest - mouse.xCurr ) * 0.05;
      mouse.yCurr += ( mouse.yDest - mouse.yCurr ) * 0.05;

      if ( horizontalOrientation === true ) {

        // HORIZONTAL SCANNING
        currentPosition += ( mouse.xCurr - currentPosition );
        if( mouse.xCurr !== lastPosition ) {
          var position = parseFloat( currentPosition / containerDimensions.w );
          position = overflowArea.x * position;
          target.style[ 'webkitTransform' ] = 'translate3d(' + position + 'px, 0px, 0px)';
          target.style[ 'MozTransform' ] = 'translate3d(' + position + 'px, 0px, 0px)';
          target.style[ 'msTransform' ] = 'translate3d(' + position + 'px, 0px, 0px)';
          lastPosition = mouse.xCurr;
        }
      } else if ( horizontalOrientation === false ) {

        // VERTICAL SCANNING
        currentPosition += ( mouse.yCurr - currentPosition );
        if( mouse.yCurr !== lastPosition ) {
          var position = parseFloat( currentPosition / containerDimensions.h );
          position = overflowArea.y * position;
          target.style[ 'webkitTransform' ] = 'translate3d( 0px, ' + position + 'px, 0px)';
          target.style[ 'MozTransform' ] = 'translate3d( 0px, ' + position + 'px, 0px)';
          target.style[ 'msTransform' ] = 'translate3d( 0px, ' + position + 'px, 0px)';
          lastPosition = mouse.yCurr;
        }
      }
    }

    function main( element ) {

      // Parse arguments

      if ( !element ) {
        throw 'You need to pass an element!';
      }

      startTracking( element );
    }

    return extend( main, {
        resize: setDimensions,
        start: start,
        stop: stop
    });

})();

  </script>
</body>